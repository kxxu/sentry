# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

status = INFO
name = HiveLog4j2
packages = org.apache.hadoop.hive.ql.log
monitorInterval = 60

# list of properties
property.hive.log.level = INFO
property.hive.root.logger = DRFA
#property.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}
property.hive.log.dir = /var/log/hive
property.hive.log.file = hive.log

# list of all appenders
appenders = console, DRFA, sentry, audit,jdbc

# console appender
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_ERR
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n

# daily rolling file appender
appender.DRFA.type = RollingFile
appender.DRFA.name = DRFA
appender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}
# Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
appender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd}
appender.DRFA.layout.type = PatternLayout
appender.DRFA.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n
appender.DRFA.policies.type = Policies
appender.DRFA.policies.time.type = TimeBasedTriggeringPolicy
appender.DRFA.policies.time.interval = 1
appender.DRFA.policies.time.modulate = true
appender.DRFA.strategy.type = DefaultRolloverStrategy
appender.DRFA.strategy.max = 30

appender.sentry.type = RollingFile
appender.sentry.name = sentry
appender.sentry.fileName = ${sys:hive.log.dir}/sentry.log
# Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
appender.sentry.filePattern = ${sys:hive.log.dir}/sentry.log.%d{yyyy-MM-dd}
appender.sentry.layout.type = PatternLayout
appender.sentry.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n
appender.sentry.policies.type = Policies
appender.sentry.policies.time.type = TimeBasedTriggeringPolicy
appender.sentry.policies.time.interval = 1
appender.sentry.policies.time.modulate = true
appender.sentry.strategy.type = DefaultRolloverStrategy
appender.sentry.strategy.max = 30

appender.audit.type = RollingFile
appender.audit.name = audit
appender.audit.fileName = ${sys:hive.log.dir}/hive-audit.log
# Use %pid in the filePattern to append <process-id>@<host-name> to the filename if you want separate log files for different CLI session
appender.audit.filePattern = ${sys:hive.log.dir}/hive-audit.log.%d{yyyy-MM-dd}
appender.audit.layout.type = PatternLayout
appender.audit.layout.pattern = %d{ISO8601}|%m%n
appender.audit.policies.type = Policies
appender.audit.policies.time.type = TimeBasedTriggeringPolicy
appender.audit.policies.time.interval = 1
appender.audit.policies.time.modulate = true
appender.audit.strategy.type = DefaultRolloverStrategy
appender.audit.strategy.max = 30

appender.jdbc.type=JDBCTable
appender.jdbc.name=jdbc
appender.jdbc.tableName=filebrowser_hive_table
appender.jdbc.ignoreExceptions=true
appender.jdbc.table_name.name=table_name
appender.jdbc.table_name.type=ColumnDesc
appender.jdbc.table_name.property=tableName
appender.jdbc.project.name=project
appender.jdbc.project.type=ColumnDesc
appender.jdbc.project.property=project
appender.jdbc.project_owner.name=project_owner
appender.jdbc.project_owner.type=ColumnDesc
appender.jdbc.project_owner.property=createUser
appender.jdbc.created_time.name=created_time
appender.jdbc.created_time.type=ColumnDesc
appender.jdbc.created_time.property=createdTime
appender.jdbc.created_time.handler=org.apache.sentry.log.handler.DateTypeHandler
appender.jdbc.table_description.name=table_description
appender.jdbc.table_description.type=ColumnDesc
appender.jdbc.table_description.property=tableDescription



# list of all loggers
loggers = Jdbc,Audit,Sentry,NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX
logger.Jdbc.name=jdbc
logger.Jdbc.level=INFO
logger.Jdbc.appenderRefs=jdbc
logger.Jdbc.appenderRef.jdbc.ref=jdbc

logger.Sentry.name = org.apache.sentry
logger.Sentry.level = DEBUG
logger.Sentry.appenderRefs = rolling
logger.Sentry.appenderRef.rolling.ref = sentry

logger.Audit.name = audit
logger.Audit.level = INFO
logger.Audit.appenderRefs = audit
logger.Audit.appenderRef.audit.ref = audit

logger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn
logger.NIOServerCnxn.level = WARN

logger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO
logger.ClientCnxnSocketNIO.level = WARN

logger.DataNucleus.name = DataNucleus
logger.DataNucleus.level = ERROR

logger.Datastore.name = Datastore
logger.Datastore.level = ERROR

logger.JPOX.name = JPOX
logger.JPOX.level = ERROR

# root logger
rootLogger.level = ${sys:hive.log.level}
rootLogger.appenderRefs = root
rootLogger.appenderRef.root.ref = ${sys:hive.root.logger}
